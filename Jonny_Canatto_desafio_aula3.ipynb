{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio - Aula 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nome: Jonny Silva Canatto\n",
    "### RM: 332439"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jonny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package floresta to\n",
      "[nltk_data]     C:\\Users\\jonny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package floresta is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Realizando todos os imports necessários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import os, importlib\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import floresta\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "nltk.download('floresta')\n",
    "stops = nltk.corpus.stopwords.words('english')\n",
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Crie uma classe de tratamento de texto. A classe deverá conter:\n",
    "   ## -> remoção de números\n",
    "   ## -> passar o texto para caixa baixa\n",
    "   ## -> remoção de caracteres especiais\n",
    "   ## -> remoção de stop-words\n",
    "   ## -> Stemização/lemmatização (deve ser passado como parâmetro qual abordagem utilizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resposta 1\n",
    "    \n",
    "def remove_numero_caracteres_especiais(linha):\n",
    "    linha = re.sub(r'[^a-zA-Z ]+','',linha)\n",
    "    return linha\n",
    "\n",
    "def caixa_baixa(linha):\n",
    "    linha = linha.lower()\n",
    "    return linha\n",
    "\n",
    "def remove_stop_words(linha):\n",
    "    linha = ' '.join([palavra for palavra in linha.split(' ') if palavra not in stops])\n",
    "    return linha\n",
    "\n",
    "def lemmatizacao(linha):\n",
    "\n",
    "    linha = ' '.join([wnl.lemmatize(palavra, 'v') for palavra in linha.split(' ')])\n",
    "    return linha\n",
    "\n",
    "def stemizacao(linha):\n",
    "    linha = ' '.join([ps.stem(palavra) for palavra in word_tokenize(linha)])\n",
    "    return linha\n",
    "\n",
    "def tratarDataFrame(linha,stem = False,lem = False):\n",
    "    linha = caixa_baixa(linha)\n",
    "    linha = remove_numero_caracteres_especiais(linha)\n",
    "    linha = remove_stop_words(linha)\n",
    "    if(stem):\n",
    "        linha = stemizacao(linha)\n",
    "    if(lem):\n",
    "        linha = lemmatizacao(linha)\n",
    "    return linha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Refaça o exercício de aula (movie_review) realizando o tratamento do texto antes. Houve diferença? Descreva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualização dos dados:\n",
      "                                                text  tag\n",
      "0  film adapt comic book plenti success whether t...    1\n",
      "1  starter creat alan moor eddi campbel brought m...    1\n",
      "2  say moor campbel thoroughli research subject j...    1\n",
      "3  book graphic novel page long includ nearli con...    1\n",
      "4                       word dont dismiss film sourc    1\n",
      "------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69      9561\n",
      "           1       0.69      0.75      0.72      9855\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     19416\n",
      "   macro avg       0.71      0.70      0.70     19416\n",
      "weighted avg       0.71      0.70      0.70     19416\n",
      "\n",
      "------------------------\n",
      "0.7047280593325093\n"
     ]
    }
   ],
   "source": [
    "# resposta 2\n",
    "\n",
    "#Leitura do dataFrame\n",
    "data = pd.read_csv('movie_review1.csv',index_col=0)\n",
    "\n",
    "#Limpeza dos dados\n",
    "data['text'] = [tratarDataFrame(txt, True, False) for txt in data['text']]\n",
    "\n",
    "print('Visualização dos dados:')\n",
    "print(data.head())\n",
    "print('------------------------')\n",
    "#Montando BOW\n",
    "vet = TfidfVectorizer()\n",
    "bow = vet.fit_transform(data['text'])\n",
    "\n",
    "#Definições de treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow, data['tag'], test_size=0.3, random_state=69, shuffle = True)\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "#Resultados\n",
    "print(classification_report(y_test, predicted))\n",
    "\n",
    "print('------------------------')\n",
    "\n",
    "print(np.mean(predicted == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O Precision e o Recal estão com valores próximos, o classificador está bom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Utilizando o dataset disposto no portal, faça:\n",
    "   ## -> extraia o dataset na pasta do notebook\n",
    "   ## -> crie uma função que leia o conteúdo de cada uma das pastas, amazene num dataframe com duas colunas (review, tag)\n",
    "   ## -> utilize a classe de tratamento de texto criada acima para tratar o texto\n",
    "   ## -> crie um pipeline de classificação de texto (countvectorizer/tfidfvectorizer,divisão em treino/teste,instância de modelo, fit e predict)\n",
    "   ## -> imprima o relatório de classificação\n",
    "   ## -> OBS: teste várias opções de stemming/lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review      tag\n",
      "0  films adapted from comic books have had plenty...  postive\n",
      "1  every now and then a movie comes along from a ...  postive\n",
      "2  you've got mail works alot better than it dese...  postive\n",
      "3   \" jaws \" is a rare film that grabs your atten...  postive\n",
      "4  moviemaking is a lot like being the general ma...  postive\n"
     ]
    }
   ],
   "source": [
    "# resposta 3\n",
    "\n",
    "#Criando o dataFrame\n",
    "df = pd.DataFrame(columns=['review','tag'])\n",
    "\n",
    "#Leitura das pastas\n",
    "for file in os.listdir(\"pos\"):\n",
    "    pasta = open(\"pos/\"+ file,'r')\n",
    "    df = df.append({'review':pasta.read(),'tag':'postive'}, ignore_index=True)\n",
    "        \n",
    "for file in os.listdir(\"neg\"):\n",
    "    pasta = open(\"neg/\"+file,'r')\n",
    "    df = df.append({'review':pasta.read(),'tag':'negative'}, ignore_index=True)\n",
    "    \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualização\n",
      "                                              review      tag\n",
      "0  film adapt comic book plenti success whether t...  postive\n",
      "1  everi movi come along suspect studio everi ind...  postive\n",
      "2  youv got mail work alot better deserv order ma...  postive\n",
      "3  jaw rare film grab attent show singl imag scre...  postive\n",
      "4  moviemak lot like gener manag nfl team postsal...  postive\n",
      " \n",
      "---stemização---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.85      0.77       287\n",
      "     postive       0.83      0.67      0.74       313\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       600\n",
      "   macro avg       0.77      0.76      0.76       600\n",
      "weighted avg       0.77      0.76      0.76       600\n",
      "\n",
      "Acurácia: 0.7566666666666667\n"
     ]
    }
   ],
   "source": [
    "#Com stemização\n",
    "df_stem = df\n",
    "df_stem['review'] = [tratarDataFrame(txt, True, False) for txt in df['review']]\n",
    "\n",
    "print('Visualização')\n",
    "print(df_stem.head())\n",
    "print(' ')\n",
    "vec = TfidfVectorizer()\n",
    "bow = vec.fit_transform(df_stem['review'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow, df_stem['tag'], test_size=0.3, random_state=69, shuffle = True)\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "print('---stemização---')\n",
    "print(classification_report(y_test, predicted))\n",
    "print('Acurácia:',np.mean(predicted == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---lemmatização---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.85      0.78       287\n",
      "     postive       0.84      0.68      0.75       313\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       600\n",
      "   macro avg       0.77      0.77      0.76       600\n",
      "weighted avg       0.78      0.76      0.76       600\n",
      "\n",
      "Acurácia: 0.7633333333333333\n"
     ]
    }
   ],
   "source": [
    "#Com lemmatização\n",
    "df_lem = df\n",
    "df_lem['review'] = [tratarDataFrame(txt, False, True) for txt in df['review']]\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "bow = vec.fit_transform(df_lem['review'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow, df_lem['tag'], test_size=0.3, random_state=69, shuffle = True)\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "print('---lemmatização---')\n",
    "print(classification_report(y_test, predicted))\n",
    "print('Acurácia:',np.mean(predicted == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualização\n",
      "                                              review      tag\n",
      "0  film adapt comic book plenti success whether t...  postive\n",
      "1  everi movi come along suspect studio everi ind...  postive\n",
      "2  youv get mail work alot better deserv order ma...  postive\n",
      "3  jaw rare film grab attent show singl imag scre...  postive\n",
      "4  moviemak lot like gener manag nfl team postsal...  postive\n",
      " \n",
      "---ambo---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.85      0.78       287\n",
      "     postive       0.84      0.68      0.75       313\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       600\n",
      "   macro avg       0.77      0.77      0.76       600\n",
      "weighted avg       0.78      0.76      0.76       600\n",
      "\n",
      "Acurácia: 0.7633333333333333\n"
     ]
    }
   ],
   "source": [
    "#Com Ambos\n",
    "df_lem_stem = df\n",
    "df_lem_stem['review'] = [tratarDataFrame(txt, True, True) for txt in df['review']]\n",
    "\n",
    "print('Visualização')\n",
    "print(df_lem_stem.head())\n",
    "print(' ')\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "bow = vec.fit_transform(df_lem_stem['review'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow, df_lem_stem['tag'], test_size=0.3, random_state=69, shuffle = True)\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "print('---ambo---')\n",
    "print(classification_report(y_test, predicted))\n",
    "print('Acurácia:',np.mean(predicted == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
