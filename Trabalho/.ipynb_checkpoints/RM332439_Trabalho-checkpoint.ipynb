{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RM:332439\n",
    "## Nome: Jonny Silva Canatto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonny\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "C:\\Users\\jonny\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "#!pip install pprint\n",
    "#!pip install pyLDAvis\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!python -m spacy download en_core_web_sm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import gensim\n",
    "import multiprocessing\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "import string\n",
    "import gensim.corpora as corpora\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import warnings\n",
    "\n",
    "from pprint import pprint\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do CSV e visualização do Dataframe\n",
    "df = pd.read_csv('movies.csv')\n",
    "df = df['title']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remoção do ano no título\n",
    "df2 = [title.split('(')[0].lower().strip() for title in df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-2. Implementando Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Querys da busca\n",
    "querys = ['toy story','the lion king','alladin','beauty and the best','cinderella','little mermaid','hercules']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monta DTM do corpus\n",
    "vect = CountVectorizer(ngram_range=(1,1))\n",
    "vect.fit(df2)\n",
    "DTM = vect.transform(df2)\n",
    "\n",
    "#Monta DTM do vetor de caracteristicas\n",
    "DTM_ajustado = vect.transform(querys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o score\n",
    "c = 2\n",
    "\n",
    "xij = DTM_ajustado\n",
    "X = DTM\n",
    "m = np.mean(X, 0)\n",
    "n = len(querys)\n",
    "\n",
    "a = c * m\n",
    "a_ = a + xij.sum(0)\n",
    "b = c * (1 - m)\n",
    "b_ = b + n - xij.sum(0)\n",
    "\n",
    "q = np.log(a_) - np.log(a) - np.log(b_) + np.log(b)\n",
    "\n",
    "nc = ((np.log(a+b) - np.log(a + b + n) + np.log(b_)) - np.log(b)).sum(1)\n",
    "\n",
    "s = nc + (X*q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o dataframe\n",
    "data = pd.DataFrame({'title':df2, 'score':np.asarray(s).tolist()})\n",
    "data.sort_values('score', ascending = False).iloc[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movie_review.csv')\n",
    "df = df[['text', 'tag']]\n",
    "df = shuffle(df)\n",
    "df = df.reset_index(drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TreatText(data):\n",
    "    #import pdb; pdb.set_trace()\n",
    "    stops = set(stopwords.words(\"english\"))  # melhora a performance convertendo num set\n",
    "    data['text'] = [re.sub(\"[^a-zA-Z]\", \" \",data['text'][i]) for i in range(len(data))] #mantém apenas letras (há números, links, etc.)     \n",
    "    data['text'] = [word_tokenize(data['text'][i].lower()) for i in range(len(data))] # caixa baixa\n",
    "    data['text'] = [[w for w in data['text'][i] if w not in stops]for i in range(len(data))]# remove stop words\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = TreatText(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df['tag']) # label para cada uma das frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parâmetros do word2vec\n",
    "dim_vec = 300\n",
    "min_count = 10 #retira as palavras com poucas o corrências\n",
    "window = 4 #número de palavras adjacentes\n",
    "num_workers = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instância do Word2Vec\n",
    "modelo = Word2Vec(df[\"text\"],\n",
    "                    min_count = min_count, \n",
    "                    size = dim_vec, \n",
    "                    window = window,\n",
    "                    workers = num_workers,\n",
    "                    sg = 1) #sg = 0 -> CBOW e sg = 1 -> skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanVector(model,phrase):\n",
    "    vocab = model.wv.vocab\n",
    "    phrase = \" \".join(phrase)\n",
    "    phrase = [x for x in word_tokenize(phrase) if x in vocab]\n",
    "    #Quando não houver palavra o vector recebe 0 para todas as posições\n",
    "    if phrase == []:\n",
    "        vetor = [0.0]*dim_vec \n",
    "    else: \n",
    "        #Caso contrário, calculando a matriz da frase\n",
    "        vetor = np.mean([model[word] for word in phrase],axis=0)\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFeatures(base): \n",
    "    features = [meanVector(modelo,base['text'][i])for i in range(len(base))]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = createFeatures(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[0:100000], labels[0:100000], test_size=0.3,random_state=109)\n",
    "clf = svm.SVC(kernel='linear') \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 Score:\",metrics.f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Word2Vec_skipgram.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movie_review.csv')\n",
    "df = df[['text', 'tag']]\n",
    "df = shuffle(df)\n",
    "df = df.reset_index(drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = TreatText(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df['tag']) # label para cada uma das frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parâmetros do word2vec\n",
    "dim_vec = 300\n",
    "min_count = 10 #retira as palavras com poucas o corrências\n",
    "window = 4 #número de palavras adjacentes\n",
    "num_workers = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instância do Word2Vec\n",
    "modelo = Word2Vec(df[\"text\"],\n",
    "                    min_count = min_count, \n",
    "                    size = dim_vec, \n",
    "                    window = window,\n",
    "                    workers = num_workers,\n",
    "                    sg = 0) #sg = 0 -> CBOW e sg = 1 -> skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = createFeatures(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[0:100000], labels[0:100000], test_size=0.3,random_state=109)\n",
    "clf = svm.SVC(kernel='linear') \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 Score:\",metrics.f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Word2Vec_cbow.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analise\n",
    "Skip gram atingiu um F1 score de: [0.54629252 0.6414642 ] <br />\n",
    "CBOW atingiu um F1 score de: [0.43923016 0.64040575]<br /><br />\n",
    "O Skip gram atingiu uma melhor pontuação no F1 Score tanto na analise das críticas positivas, quanto na análise das criticas negativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so how does it stack up ?</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>on this advice , director john frankenheimer (...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the big lebowski a film review by michael redm...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the only problem is the bit of typecasting tha...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the last five minutes of this movie are the wo...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tag\n",
       "0                          so how does it stack up ?  pos\n",
       "1  on this advice , director john frankenheimer (...  pos\n",
       "2  the big lebowski a film review by michael redm...  pos\n",
       "3  the only problem is the bit of typecasting tha...  pos\n",
       "4  the last five minutes of this movie are the wo...  neg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('movie_review.csv')\n",
    "df = df[['text', 'tag']]\n",
    "df = shuffle(df)\n",
    "df = df.reset_index(drop = True)\n",
    "stop_words = stopwords.words('english')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['so how does it stack up ?']\n",
      "[['so', 'how', 'does', 'it', 'stack', 'up']]\n"
     ]
    }
   ],
   "source": [
    "# Converte para lista\n",
    "data = df.text.values.tolist()\n",
    "\n",
    "# Remove Emails\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "# Remove caracter de nova linha\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove aspas simples\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:1])\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True remove pontuação\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonny\\Anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['so', 'how', 'does', 'it', 'stack', 'up']\n"
     ]
    }
   ],
   "source": [
    "# cria modelos bigrama e trigrama\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # quanto maior o threshold menos frases\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Maneira mais rápida de obter uma sentença como um trigrama / bigrama\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# exemplo trigrama\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['stack']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# cria Bigramas\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# inicia o spacy, mantenddo apenas o tagger (eficiência)\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# faz lemmatização mantendo apenas substantivo, adjetivo, verbo, advérbio\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# cria o dicionário\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Cria o corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=2, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.034*\"film\" + 0.014*\"character\" + 0.011*\"good\" + 0.008*\"even\" + '\n",
      "  '0.006*\"find\" + 0.006*\"give\" + 0.006*\"way\" + 0.005*\"little\" + 0.005*\"life\" + '\n",
      "  '0.005*\"seem\"'),\n",
      " (1,\n",
      "  '0.019*\"movie\" + 0.017*\"not\" + 0.011*\"s\" + 0.010*\"get\" + 0.010*\"make\" + '\n",
      "  '0.009*\"do\" + 0.009*\"see\" + 0.008*\"scene\" + 0.007*\"go\" + 0.007*\"be\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonny\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el71441615115566200294979895\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el71441615115566200294979895_data = {\"mdsDat\": {\"x\": [0.148082822561264, -0.148082822561264], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [55.325199127197266, 44.6748046875]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"Freq\": [10488.0, 6049.0, 6804.0, 4060.0, 3896.0, 3735.0, 3477.0, 3349.0, 3148.0, 2497.0, 2480.0, 1797.0, 1760.0, 2896.0, 2336.0, 2189.0, 3733.0, 2029.0, 1481.0, 2001.0, 1865.0, 1800.0, 1885.0, 1569.0, 2144.0, 2029.0, 1215.0, 1458.0, 1194.0, 1121.0, 6044.71142578125, 3346.87353515625, 3892.586181640625, 2477.066650390625, 1328.8646240234375, 3727.578857421875, 1461.933349609375, 1861.16455078125, 1441.2733154296875, 1158.7286376953125, 3138.83837890625, 1426.2236328125, 2023.4644775390625, 823.782470703125, 767.0111694335938, 1142.0150146484375, 818.2244262695312, 1198.5252685546875, 1993.02978515625, 849.336669921875, 775.05615234375, 843.1156005859375, 673.0872802734375, 1014.4559326171875, 916.1800537109375, 709.3783569335938, 1278.921142578125, 568.868408203125, 921.41259765625, 1470.2764892578125, 6723.34228515625, 2177.498779296875, 2316.5693359375, 1872.728271484375, 1465.541748046875, 2826.166748046875, 1415.7559814453125, 1339.870849609375, 1988.497802734375, 2090.9912109375, 1398.1160888671875, 1502.6878662109375, 3466.48193359375, 1633.687255859375, 2522.321044921875, 1583.4066162109375, 1521.1900634765625, 1739.693359375, 1491.7110595703125, 1756.2406005859375, 1118.0701904296875, 1792.196044921875, 733.7254028320312, 1037.4423828125, 542.155029296875, 822.7063598632812, 1207.9774169921875, 494.0147705078125, 512.6415405273438, 534.2631225585938, 347.21136474609375, 591.7496948242188, 528.07421875, 332.8262023925781, 531.4437255859375, 364.6061706542969, 414.69586181640625, 403.9033508300781, 1468.695556640625, 335.8404541015625, 501.73724365234375, 472.2242126464844, 492.947998046875, 677.3505859375, 410.0503845214844, 283.9992980957031, 728.9013061523438, 396.4212951660156, 338.95989990234375, 3976.48974609375, 1179.688720703125, 1043.394287109375, 911.82080078125, 10084.2890625, 895.188232421875, 660.847900390625, 549.29833984375, 1116.5927734375, 590.2521362304688, 3266.379638671875, 2345.413330078125, 1497.0335693359375, 1393.320556640625, 1681.58056640625, 828.4905395507812, 971.5755004882812, 1322.7227783203125, 1177.4625244140625, 810.5579833984375, 794.0023193359375, 806.1375122070312, 762.8663330078125, 846.3707275390625, 850.6549682617188, 1078.9874267578125], \"Term\": [\"film\", \"not\", \"movie\", \"character\", \"s\", \"get\", \"good\", \"do\", \"see\", \"even\", \"be\", \"find\", \"give\", \"scene\", \"come\", \"take\", \"make\", \"look\", \"life\", \"story\", \"much\", \"way\", \"know\", \"little\", \"play\", \"well\", \"actor\", \"seem\", \"feel\", \"performance\", \"not\", \"do\", \"s\", \"be\", \"really\", \"get\", \"thing\", \"much\", \"people\", \"there\", \"see\", \"think\", \"look\", \"tell\", \"leave\", \"could\", \"guy\", \"love\", \"story\", \"enough\", \"point\", \"kill\", \"woman\", \"day\", \"have\", \"happen\", \"show\", \"right\", \"part\", \"say\", \"movie\", \"take\", \"come\", \"know\", \"bad\", \"scene\", \"plot\", \"never\", \"well\", \"play\", \"want\", \"end\", \"make\", \"work\", \"go\", \"would\", \"first\", \"also\", \"time\", \"give\", \"performance\", \"find\", \"young\", \"use\", \"old\", \"script\", \"actor\", \"american\", \"human\", \"put\", \"black\", \"job\", \"hollywood\", \"release\", \"face\", \"base\", \"dialogue\", \"series\", \"life\", \"late\", \"picture\", \"city\", \"review\", \"cast\", \"main\", \"white\", \"follow\", \"house\", \"title\", \"character\", \"feel\", \"audience\", \"something\", \"film\", \"run\", \"screen\", \"talent\", \"year\", \"kind\", \"good\", \"even\", \"little\", \"seem\", \"way\", \"however\", \"star\", \"may\", \"many\", \"write\", \"live\", \"set\", \"begin\", \"big\", \"turn\", \"time\"], \"Total\": [10488.0, 6049.0, 6804.0, 4060.0, 3896.0, 3735.0, 3477.0, 3349.0, 3148.0, 2497.0, 2480.0, 1797.0, 1760.0, 2896.0, 2336.0, 2189.0, 3733.0, 2029.0, 1481.0, 2001.0, 1865.0, 1800.0, 1885.0, 1569.0, 2144.0, 2029.0, 1215.0, 1458.0, 1194.0, 1121.0, 6049.4658203125, 3349.602783203125, 3896.11474609375, 2480.2470703125, 1331.4290771484375, 3735.186279296875, 1465.0445556640625, 1865.6165771484375, 1444.8109130859375, 1162.0206298828125, 3148.17333984375, 1430.6051025390625, 2029.7808837890625, 826.718505859375, 769.8856811523438, 1146.4903564453125, 821.4342041015625, 1203.2901611328125, 2001.1800537109375, 852.9712524414062, 778.5845336914062, 847.05908203125, 676.2379150390625, 1019.2816772460938, 920.5696411132812, 712.8258666992188, 1285.1656494140625, 571.6915283203125, 926.2549438476562, 1478.186279296875, 6804.17919921875, 2189.7255859375, 2336.336669921875, 1885.822509765625, 1474.8555908203125, 2896.737548828125, 1431.025146484375, 1355.97705078125, 2029.90283203125, 2144.810546875, 1419.21044921875, 1530.2042236328125, 3733.96044921875, 1680.1326904296875, 2714.259765625, 1640.214599609375, 1597.297607421875, 2125.13232421875, 2570.698486328125, 1760.73046875, 1121.34521484375, 1797.760986328125, 737.5159912109375, 1043.172607421875, 545.2697143554688, 827.645263671875, 1215.9093017578125, 497.45306396484375, 516.3289184570312, 538.1621704101562, 349.8612976074219, 596.2832641601562, 532.1209106445312, 335.40838623046875, 535.7962646484375, 367.60162353515625, 418.13421630859375, 407.3770446777344, 1481.77294921875, 338.8844299316406, 506.4310302734375, 476.9574279785156, 497.9508972167969, 684.2605590820312, 414.27923583984375, 287.02142333984375, 736.8812866210938, 400.9765319824219, 342.9176025390625, 4060.974853515625, 1194.5247802734375, 1058.6434326171875, 924.8094482421875, 10488.255859375, 909.0336303710938, 669.1959228515625, 556.0626831054688, 1147.173828125, 599.412353515625, 3477.787109375, 2497.06982421875, 1569.180419921875, 1458.6658935546875, 1800.572021484375, 859.5640258789062, 1027.8553466796875, 1445.7744140625, 1277.4862060546875, 850.6490478515625, 833.9898681640625, 857.625732421875, 818.642578125, 957.4323120117188, 1043.2803955078125, 2570.698486328125], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.5911999940872192, 0.5910999774932861, 0.5910000205039978, 0.5906999707221985, 0.5899999737739563, 0.589900016784668, 0.5898000001907349, 0.5896000266075134, 0.5895000100135803, 0.5891000032424927, 0.5889999866485596, 0.5889000296592712, 0.5888000130653381, 0.5884000062942505, 0.5881999731063843, 0.5879999995231628, 0.5879999995231628, 0.5879999995231628, 0.5878999829292297, 0.5877000093460083, 0.5874000191688538, 0.5873000025749207, 0.5873000025749207, 0.5871999859809875, 0.5871999859809875, 0.5871000289916992, 0.5871000289916992, 0.5870000123977661, 0.5867000222206116, 0.5866000056266785, 0.5799999833106995, 0.5863000154495239, 0.5834000110626221, 0.5849999785423279, 0.5856000185012817, 0.567300021648407, 0.5812000036239624, 0.5799999833106995, 0.5713000297546387, 0.5665000081062317, 0.5770000219345093, 0.5738000273704529, 0.5175999999046326, 0.5638999938964844, 0.5185999870300293, 0.5566999912261963, 0.5430999994277954, 0.3917999863624573, 0.04769999906420708, 0.8032000064849854, 0.8027999997138977, 0.8026999831199646, 0.800599992275238, 0.8003000020980835, 0.800000011920929, 0.7997999787330627, 0.7991999983787537, 0.798799991607666, 0.7986000180244446, 0.7985000014305115, 0.7982000112533569, 0.7980999946594238, 0.7980999946594238, 0.7979999780654907, 0.7975999712944031, 0.7975999712944031, 0.7975000143051147, 0.7972000241279602, 0.7968999743461609, 0.7967000007629395, 0.7964000105857849, 0.795799970626831, 0.7957000136375427, 0.7955999970436096, 0.7954999804496765, 0.795199990272522, 0.7949000000953674, 0.7943000197410583, 0.7942000031471252, 0.7846999764442444, 0.7932999730110168, 0.7912999987602234, 0.7915999889373779, 0.7664999961853027, 0.7904000282287598, 0.7932000160217285, 0.7935000061988831, 0.7786999940872192, 0.7904000282287598, 0.7429999709129333, 0.7430999875068665, 0.7587000131607056, 0.7598999738693237, 0.7373999953269958, 0.7688999772071838, 0.7494000196456909, 0.7167999744415283, 0.7242000102996826, 0.7574999928474426, 0.756600022315979, 0.7437999844551086, 0.7351999878883362, 0.6825000047683716, 0.6015999913215637, -0.06239999830722809], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.094699859619141, -4.6859002113342285, -4.534800052642822, -4.986800193786621, -5.609600067138672, -4.578100204467773, -5.514100074768066, -5.27269983291626, -5.52839994430542, -5.746600151062012, -4.75, -5.53879976272583, -5.1890997886657715, -6.087699890136719, -6.15910005569458, -5.761099815368652, -6.0945000648498535, -5.712800025939941, -5.20419979095459, -6.057199954986572, -6.14870023727417, -6.064499855041504, -6.28980016708374, -5.879499912261963, -5.981400012969971, -6.237199783325195, -5.647900104522705, -6.458000183105469, -5.9756999015808105, -5.508399963378906, -3.988300085067749, -5.115699768066406, -5.053800106048584, -5.266499996185303, -5.51170015335083, -4.855000019073486, -5.546199798583984, -5.60129976272583, -5.206500053405762, -5.156199932098389, -5.558800220489502, -5.486599922180176, -4.650700092315674, -5.4029998779296875, -4.968699932098389, -5.434299945831299, -5.474400043487549, -5.340199947357178, -5.49399995803833, -5.1168999671936035, -5.56850004196167, -5.09660005569458, -5.989699840545654, -5.6433000564575195, -6.292300224304199, -5.875199794769287, -5.491099834442139, -6.385300159454346, -6.348199844360352, -6.3069000244140625, -6.7378997802734375, -6.204699993133545, -6.318600177764893, -6.780200004577637, -6.31220006942749, -6.689000129699707, -6.560299873352051, -6.586599826812744, -5.2957000732421875, -6.771200180053711, -6.369699954986572, -6.4303998947143555, -6.387400150299072, -6.0696001052856445, -6.571499824523926, -6.938799858093262, -5.996300220489502, -6.605299949645996, -6.761899948120117, -4.299699783325195, -5.514800071716309, -5.637599945068359, -5.77239990234375, -3.3691000938415527, -5.790800094604492, -6.094299793243408, -6.279200077056885, -5.569799900054932, -6.207300186157227, -4.496399879455566, -4.827600002288818, -5.276599884033203, -5.348400115966797, -5.160299777984619, -5.868199825286865, -5.708899974822998, -5.400400161743164, -5.51669979095459, -5.890100002288818, -5.910699844360352, -5.895599842071533, -5.950699806213379, -5.84689998626709, -5.841800212860107, -5.604000091552734]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.006579438224434853, 0.9934951663017273, 0.818772554397583, 0.1811651885509491, 0.006030719727277756, 0.9930585026741028, 0.014169076457619667, 0.985223114490509, 0.9939956068992615, 0.006102292332798243, 0.008161008358001709, 0.9929227232933044, 0.9986908435821533, 0.0012095569400116801, 0.06840591877698898, 0.9320306777954102, 0.11593508720397949, 0.8836134076118469, 0.008574826642870903, 0.9918216466903687, 0.010230021551251411, 0.989389181137085, 0.02068468928337097, 0.9790752530097961, 0.010483115911483765, 0.9896061420440674, 0.9917235374450684, 0.008560409769415855, 0.9960833787918091, 0.0034889085218310356, 0.9948182106018066, 0.00490541523322463, 0.007174729835242033, 0.9925042986869812, 0.9992229342460632, 0.0008956285892054439, 0.9822218418121338, 0.018298210576176643, 0.9953442215919495, 0.004689489956945181, 0.060871344059705734, 0.9391006827354431, 0.007465524133294821, 0.9910483360290527, 0.01255729515105486, 0.9878405332565308, 0.038519274443387985, 0.9614563584327698, 0.003337484784424305, 0.9967954754829407, 0.9522333145141602, 0.04758036136627197, 0.01085656601935625, 0.9893045425415039, 0.9980760812759399, 0.002141794189810753, 0.002271784469485283, 0.9973133206367493, 0.9291667938232422, 0.07073751837015152, 0.06067076325416565, 0.9391028881072998, 0.9958192706108093, 0.0036521488800644875, 0.9946328401565552, 0.0042086015455424786, 0.9950360655784607, 0.004345135763287544, 0.007517088670283556, 0.992255687713623, 0.012469558045268059, 0.9875889420509338, 0.03606479614973068, 0.9632790088653564, 0.007746999617666006, 0.9935527443885803, 0.008385276421904564, 0.9928167462348938, 0.9952080249786377, 0.004722220823168755, 0.015014705248177052, 0.9842973351478577, 0.9932006001472473, 0.006893543992191553, 0.008852575905621052, 0.9914884567260742, 0.9962518215179443, 0.003896682523190975, 0.008773273788392544, 0.991379976272583, 0.04588382691144943, 0.9540011882781982, 0.047962214797735214, 0.9520499110221863, 0.9966592788696289, 0.002955984091386199, 0.9964346289634705, 0.004155273549258709, 0.009655323810875416, 0.9896706342697144, 0.9282369613647461, 0.0715058445930481, 0.07827873528003693, 0.9213406443595886, 0.0850755125284195, 0.9150805473327637, 0.9880692362785339, 0.01190444827079773, 0.9975254535675049, 0.0021440633572638035, 0.988217294216156, 0.011799609288573265, 0.9992617964744568, 0.0008265192736871541, 0.005501864477992058, 0.9940034747123718, 0.994326651096344, 0.005398082081228495, 0.9973623156547546, 0.00276852841489017, 0.0026753582060337067, 0.9970167875289917, 0.009873013012111187, 0.9912504553794861, 0.9749112725257874, 0.02517704851925373, 0.9895004034042358, 0.010481996461749077, 0.995396077632904, 0.005137528292834759, 0.007432703860104084, 0.9922659397125244, 0.9981755614280701, 0.002253218088299036, 0.008944320492446423, 0.9928195476531982, 0.010041150264441967, 0.9900574684143066, 0.9952920079231262, 0.005247585009783506, 0.015400970354676247, 0.9845620393753052, 0.9992005228996277, 0.0010266638128086925, 0.9944619536399841, 0.005412037950009108, 0.9755802750587463, 0.024510331451892853, 0.01195464562624693, 0.9877525568008423, 0.006041235756129026, 0.9943873882293701, 0.9970861673355103, 0.002858800580725074, 0.04456126689910889, 0.9549822211265564, 0.007364185061305761, 0.9917102456092834, 0.05946649983525276, 0.9398038983345032, 0.9952024221420288, 0.0046686590649187565, 0.014056949876248837, 0.9861490726470947, 0.05448237434029579, 0.9456583857536316, 0.9959123730659485, 0.003997641149908304, 0.9941884875297546, 0.005480138584971428, 0.012588508427143097, 0.9872987866401672, 0.9967116713523865, 0.003628804814070463, 0.9974005222320557, 0.002581709763035178, 0.997921884059906, 0.0020477192010730505, 0.9967809915542603, 0.002796019660308957, 0.5803869962692261, 0.4197302758693695, 0.011664609424769878, 0.9885756969451904, 0.1849934160709381, 0.8156963586807251, 0.00575168477371335, 0.9940828680992126, 0.9850547313690186, 0.014796960167586803, 0.06609010696411133, 0.9341475963592529, 0.9793572425842285, 0.02019801177084446, 0.010452181100845337, 0.9894731640815735, 0.9952118992805481, 0.004436308518052101, 0.9725422263145447, 0.027378790080547333, 0.9651176333427429, 0.03475154936313629, 0.04702291637659073, 0.9533896446228027, 0.02702293172478676, 0.9736972451210022, 0.005423611029982567, 0.9952326416969299], \"Term\": [\"actor\", \"actor\", \"also\", \"also\", \"american\", \"american\", \"audience\", \"audience\", \"bad\", \"bad\", \"base\", \"base\", \"be\", \"be\", \"begin\", \"begin\", \"big\", \"big\", \"black\", \"black\", \"cast\", \"cast\", \"character\", \"character\", \"city\", \"city\", \"come\", \"come\", \"could\", \"could\", \"day\", \"day\", \"dialogue\", \"dialogue\", \"do\", \"do\", \"end\", \"end\", \"enough\", \"enough\", \"even\", \"even\", \"face\", \"face\", \"feel\", \"feel\", \"film\", \"film\", \"find\", \"find\", \"first\", \"first\", \"follow\", \"follow\", \"get\", \"get\", \"give\", \"give\", \"go\", \"go\", \"good\", \"good\", \"guy\", \"guy\", \"happen\", \"happen\", \"have\", \"have\", \"hollywood\", \"hollywood\", \"house\", \"house\", \"however\", \"however\", \"human\", \"human\", \"job\", \"job\", \"kill\", \"kill\", \"kind\", \"kind\", \"know\", \"know\", \"late\", \"late\", \"leave\", \"leave\", \"life\", \"life\", \"little\", \"little\", \"live\", \"live\", \"look\", \"look\", \"love\", \"love\", \"main\", \"main\", \"make\", \"make\", \"many\", \"many\", \"may\", \"may\", \"movie\", \"movie\", \"much\", \"much\", \"never\", \"never\", \"not\", \"not\", \"old\", \"old\", \"part\", \"part\", \"people\", \"people\", \"performance\", \"performance\", \"picture\", \"picture\", \"play\", \"play\", \"plot\", \"plot\", \"point\", \"point\", \"put\", \"put\", \"really\", \"really\", \"release\", \"release\", \"review\", \"review\", \"right\", \"right\", \"run\", \"run\", \"s\", \"s\", \"say\", \"say\", \"scene\", \"scene\", \"screen\", \"screen\", \"script\", \"script\", \"see\", \"see\", \"seem\", \"seem\", \"series\", \"series\", \"set\", \"set\", \"show\", \"show\", \"something\", \"something\", \"star\", \"star\", \"story\", \"story\", \"take\", \"take\", \"talent\", \"talent\", \"tell\", \"tell\", \"there\", \"there\", \"thing\", \"thing\", \"think\", \"think\", \"time\", \"time\", \"title\", \"title\", \"turn\", \"turn\", \"use\", \"use\", \"want\", \"want\", \"way\", \"way\", \"well\", \"well\", \"white\", \"white\", \"woman\", \"woman\", \"work\", \"work\", \"would\", \"would\", \"write\", \"write\", \"year\", \"year\", \"young\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el71441615115566200294979895\", ldavis_el71441615115566200294979895_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el71441615115566200294979895\", ldavis_el71441615115566200294979895_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el71441615115566200294979895\", ldavis_el71441615115566200294979895_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x    y  topics  cluster       Freq\n",
       "topic                                           \n",
       "1      0.148083  0.0       1        1  55.325199\n",
       "0     -0.148083  0.0       2        1  44.674805, topic_info=     Category          Freq         Term         Total  loglift  logprob\n",
       "6     Default  10488.000000         film  10488.000000  30.0000  30.0000\n",
       "159   Default   6049.000000          not   6049.000000  29.0000  29.0000\n",
       "27    Default   6804.000000        movie   6804.000000  28.0000  28.0000\n",
       "281   Default   4060.000000    character   4060.000000  27.0000  27.0000\n",
       "49    Default   3896.000000            s   3896.000000  26.0000  26.0000\n",
       "106   Default   3735.000000          get   3735.000000  25.0000  25.0000\n",
       "436   Default   3477.000000         good   3477.000000  24.0000  24.0000\n",
       "224   Default   3349.000000           do   3349.000000  23.0000  23.0000\n",
       "308   Default   3148.000000          see   3148.000000  22.0000  22.0000\n",
       "154   Default   2497.000000         even   2497.000000  21.0000  21.0000\n",
       "310   Default   2480.000000           be   2480.000000  20.0000  20.0000\n",
       "492   Default   1797.000000         find   1797.000000  19.0000  19.0000\n",
       "242   Default   1760.000000         give   1760.000000  18.0000  18.0000\n",
       "412   Default   2896.000000        scene   2896.000000  17.0000  17.0000\n",
       "282   Default   2336.000000         come   2336.000000  16.0000  16.0000\n",
       "512   Default   2189.000000         take   2189.000000  15.0000  15.0000\n",
       "227   Default   3733.000000         make   3733.000000  14.0000  14.0000\n",
       "410   Default   2029.000000         look   2029.000000  13.0000  13.0000\n",
       "158   Default   1481.000000         life   1481.000000  12.0000  12.0000\n",
       "278   Default   2001.000000        story   2001.000000  11.0000  11.0000\n",
       "28    Default   1865.000000         much   1865.000000  10.0000  10.0000\n",
       "111   Default   1800.000000          way   1800.000000   9.0000   9.0000\n",
       "210   Default   1885.000000         know   1885.000000   8.0000   8.0000\n",
       "546   Default   1569.000000       little   1569.000000   7.0000   7.0000\n",
       "12    Default   2144.000000         play   2144.000000   6.0000   6.0000\n",
       "147   Default   2029.000000         well   2029.000000   5.0000   5.0000\n",
       "538   Default   1215.000000        actor   1215.000000   4.0000   4.0000\n",
       "325   Default   1458.000000         seem   1458.000000   3.0000   3.0000\n",
       "1114  Default   1194.000000         feel   1194.000000   2.0000   2.0000\n",
       "42    Default   1121.000000  performance   1121.000000   1.0000   1.0000\n",
       "...       ...           ...          ...           ...      ...      ...\n",
       "414    Topic2    283.999298        white    287.021423   0.7952  -6.9388\n",
       "1104   Topic2    728.901306       follow    736.881287   0.7949  -5.9963\n",
       "562    Topic2    396.421295        house    400.976532   0.7943  -6.6053\n",
       "182    Topic2    338.959900        title    342.917603   0.7942  -6.7619\n",
       "281    Topic2   3976.489746    character   4060.974854   0.7847  -4.2997\n",
       "1114   Topic2   1179.688721         feel   1194.524780   0.7933  -5.5148\n",
       "569    Topic2   1043.394287     audience   1058.643433   0.7913  -5.6376\n",
       "94     Topic2    911.820801    something    924.809448   0.7916  -5.7724\n",
       "6      Topic2  10084.289062         film  10488.255859   0.7665  -3.3691\n",
       "92     Topic2    895.188232          run    909.033630   0.7904  -5.7908\n",
       "1226   Topic2    660.847900       screen    669.195923   0.7932  -6.0943\n",
       "674    Topic2    549.298340       talent    556.062683   0.7935  -6.2792\n",
       "269    Topic2   1116.592773         year   1147.173828   0.7787  -5.5698\n",
       "89     Topic2    590.252136         kind    599.412354   0.7904  -6.2073\n",
       "436    Topic2   3266.379639         good   3477.787109   0.7430  -4.4964\n",
       "154    Topic2   2345.413330         even   2497.069824   0.7431  -4.8276\n",
       "546    Topic2   1497.033569       little   1569.180420   0.7587  -5.2766\n",
       "325    Topic2   1393.320557         seem   1458.665894   0.7599  -5.3484\n",
       "111    Topic2   1681.580566          way   1800.572021   0.7374  -5.1603\n",
       "226    Topic2    828.490540      however    859.564026   0.7689  -5.8682\n",
       "551    Topic2    971.575500         star   1027.855347   0.7494  -5.7089\n",
       "564    Topic2   1322.722778          may   1445.774414   0.7168  -5.4004\n",
       "262    Topic2   1177.462524         many   1277.486206   0.7242  -5.5167\n",
       "498    Topic2    810.557983        write    850.649048   0.7575  -5.8901\n",
       "247    Topic2    794.002319         live    833.989868   0.7566  -5.9107\n",
       "326    Topic2    806.137512          set    857.625732   0.7438  -5.8956\n",
       "1347   Topic2    762.866333        begin    818.642578   0.7352  -5.9507\n",
       "834    Topic2    846.370728          big    957.432312   0.6825  -5.8469\n",
       "904    Topic2    850.654968         turn   1043.280396   0.6016  -5.8418\n",
       "399    Topic2   1078.987427         time   2570.698486  -0.0624  -5.6040\n",
       "\n",
       "[135 rows x 6 columns], token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "538       1  0.006579      actor\n",
       "538       2  0.993495      actor\n",
       "230       1  0.818773       also\n",
       "230       2  0.181165       also\n",
       "400       1  0.006031   american\n",
       "400       2  0.993059   american\n",
       "569       1  0.014169   audience\n",
       "569       2  0.985223   audience\n",
       "20        1  0.993996        bad\n",
       "20        2  0.006102        bad\n",
       "113       1  0.008161       base\n",
       "113       2  0.992923       base\n",
       "310       1  0.998691         be\n",
       "310       2  0.001210         be\n",
       "1347      1  0.068406      begin\n",
       "1347      2  0.932031      begin\n",
       "834       1  0.115935        big\n",
       "834       2  0.883613        big\n",
       "557       1  0.008575      black\n",
       "557       2  0.991822      black\n",
       "667       1  0.010230       cast\n",
       "667       2  0.989389       cast\n",
       "281       1  0.020685  character\n",
       "281       2  0.979075  character\n",
       "1302      1  0.010483       city\n",
       "1302      2  0.989606       city\n",
       "282       1  0.991724       come\n",
       "282       2  0.008560       come\n",
       "499       1  0.996083      could\n",
       "499       2  0.003489      could\n",
       "...     ...       ...        ...\n",
       "287       1  0.996781      think\n",
       "287       2  0.002796      think\n",
       "399       1  0.580387       time\n",
       "399       2  0.419730       time\n",
       "182       1  0.011665      title\n",
       "182       2  0.988576      title\n",
       "904       1  0.184993       turn\n",
       "904       2  0.815696       turn\n",
       "255       1  0.005752        use\n",
       "255       2  0.994083        use\n",
       "289       1  0.985055       want\n",
       "289       2  0.014797       want\n",
       "111       1  0.066090        way\n",
       "111       2  0.934148        way\n",
       "147       1  0.979357       well\n",
       "147       2  0.020198       well\n",
       "414       1  0.010452      white\n",
       "414       2  0.989473      white\n",
       "394       1  0.995212      woman\n",
       "394       2  0.004436      woman\n",
       "162       1  0.972542       work\n",
       "162       2  0.027379       work\n",
       "34        1  0.965118      would\n",
       "34        2  0.034752      would\n",
       "498       1  0.047023      write\n",
       "498       2  0.953390      write\n",
       "269       1  0.027023       year\n",
       "269       2  0.973697       year\n",
       "487       1  0.005424      young\n",
       "487       2  0.995233      young\n",
       "\n",
       "[208 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analise\n",
    "\n",
    "Através da visualização do agrupamento criado, é possível que o LDA obteve exíto em classificar reviews com sentimentos negativos e reviews com sentimentos posítivos.\n",
    "Obteve uma excelente perfomance por os circulos criados (agrupamentos) não possuem qualquer intersecção, portanto, as reviews foram agrupadas em 2 grupos bem distintos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
